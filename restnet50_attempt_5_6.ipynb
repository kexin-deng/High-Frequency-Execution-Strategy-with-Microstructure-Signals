{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVhCC0Oaq1Xn",
        "outputId": "4940d482-80de-460c-e4fc-3ab061c705e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch   1/50 | TrainLoss=0.4897 ValF1=0.8418@0.46 | ValAcc=0.8305 ValAUC=0.9186\n",
            "  âœ… New best model at epoch 1! Saved to 'siamese_resnet50_best.pt'\n",
            "Epoch   2/50 | TrainLoss=0.3370 ValF1=0.8713@0.38 | ValAcc=0.8632 ValAUC=0.9470\n",
            "  âœ… New best model at epoch 2! Saved to 'siamese_resnet50_best.pt'\n",
            "Epoch   3/50 | TrainLoss=0.2803 ValF1=0.8876@0.49 | ValAcc=0.8838 ValAUC=0.9591\n",
            "  âœ… New best model at epoch 3! Saved to 'siamese_resnet50_best.pt'\n",
            "Epoch   4/50 | TrainLoss=0.2294 ValF1=0.8924@0.42 | ValAcc=0.8876 ValAUC=0.9592\n",
            "  âœ… New best model at epoch 4! Saved to 'siamese_resnet50_best.pt'\n",
            "Epoch   5/50 | TrainLoss=0.1905 ValF1=0.8928@0.50 | ValAcc=0.8902 ValAUC=0.9620\n",
            "  âœ… New best model at epoch 5! Saved to 'siamese_resnet50_best.pt'\n",
            "Epoch   6/50 | TrainLoss=0.1472 ValF1=0.8949@0.31 | ValAcc=0.8904 ValAUC=0.9635\n",
            "  âœ… New best model at epoch 6! Saved to 'siamese_resnet50_best.pt'\n",
            "Epoch   7/50 | TrainLoss=0.1200 ValF1=0.8960@0.30 | ValAcc=0.8912 ValAUC=0.9646\n",
            "  âœ… New best model at epoch 7! Saved to 'siamese_resnet50_best.pt'\n",
            "Epoch   8/50 | TrainLoss=0.0985 ValF1=0.9003@0.31 | ValAcc=0.8966 ValAUC=0.9660\n",
            "  âœ… New best model at epoch 8! Saved to 'siamese_resnet50_best.pt'\n",
            "Epoch   9/50 | TrainLoss=0.0762 ValF1=0.9005@0.26 | ValAcc=0.8964 ValAUC=0.9661\n",
            "  âœ… New best model at epoch 9! Saved to 'siamese_resnet50_best.pt'\n",
            "Epoch  10/50 | TrainLoss=0.0697 ValF1=0.8998@0.34 | ValAcc=0.8966 ValAUC=0.9661\n",
            "Epoch  11/50 | TrainLoss=0.1420 ValF1=0.8953@0.39 | ValAcc=0.8916 ValAUC=0.9612\n",
            "Epoch  12/50 | TrainLoss=0.1345 ValF1=0.8949@0.34 | ValAcc=0.8921 ValAUC=0.9610\n",
            "Epoch  13/50 | TrainLoss=0.1218 ValF1=0.8911@0.61 | ValAcc=0.8901 ValAUC=0.9621\n",
            "Epoch  14/50 | TrainLoss=0.1055 ValF1=0.8952@0.51 | ValAcc=0.8926 ValAUC=0.9630\n",
            "Epoch  15/50 | TrainLoss=0.0942 ValF1=0.8934@0.24 | ValAcc=0.8881 ValAUC=0.9618\n",
            "Epoch  16/50 | TrainLoss=0.0788 ValF1=0.8953@0.54 | ValAcc=0.8919 ValAUC=0.9611\n",
            "Epoch  17/50 | TrainLoss=0.0697 ValF1=0.8949@0.48 | ValAcc=0.8936 ValAUC=0.9608\n",
            "Epoch  18/50 | TrainLoss=0.0615 ValF1=0.8948@0.29 | ValAcc=0.8904 ValAUC=0.9614\n",
            "Epoch  19/50 | TrainLoss=0.0517 ValF1=0.8994@0.45 | ValAcc=0.8961 ValAUC=0.9620\n",
            "Epoch  20/50 | TrainLoss=0.0429 ValF1=0.8969@0.10 | ValAcc=0.8908 ValAUC=0.9627\n",
            "Epoch  21/50 | TrainLoss=0.0383 ValF1=0.8989@0.38 | ValAcc=0.8956 ValAUC=0.9614\n",
            "Epoch  22/50 | TrainLoss=0.0340 ValF1=0.9003@0.51 | ValAcc=0.8990 ValAUC=0.9628\n",
            "Epoch  23/50 | TrainLoss=0.0280 ValF1=0.9011@0.23 | ValAcc=0.8968 ValAUC=0.9629\n",
            "  âœ… New best model at epoch 23! Saved to 'siamese_resnet50_best.pt'\n",
            "Epoch  24/50 | TrainLoss=0.0231 ValF1=0.8993@0.26 | ValAcc=0.8958 ValAUC=0.9629\n",
            "Epoch  25/50 | TrainLoss=0.0178 ValF1=0.9016@0.43 | ValAcc=0.9000 ValAUC=0.9624\n",
            "  âœ… New best model at epoch 25! Saved to 'siamese_resnet50_best.pt'\n",
            "Epoch  26/50 | TrainLoss=0.0154 ValF1=0.9026@0.27 | ValAcc=0.8992 ValAUC=0.9617\n",
            "  âœ… New best model at epoch 26! Saved to 'siamese_resnet50_best.pt'\n",
            "Epoch  27/50 | TrainLoss=0.0158 ValF1=0.9039@0.45 | ValAcc=0.9020 ValAUC=0.9621\n",
            "  âœ… New best model at epoch 27! Saved to 'siamese_resnet50_best.pt'\n",
            "Epoch  28/50 | TrainLoss=0.0132 ValF1=0.9041@0.39 | ValAcc=0.9020 ValAUC=0.9627\n",
            "  âœ… New best model at epoch 28! Saved to 'siamese_resnet50_best.pt'\n",
            "Epoch  29/50 | TrainLoss=0.0119 ValF1=0.9048@0.31 | ValAcc=0.9021 ValAUC=0.9623\n",
            "  âœ… New best model at epoch 29! Saved to 'siamese_resnet50_best.pt'\n",
            "Epoch  30/50 | TrainLoss=0.0101 ValF1=0.9045@0.38 | ValAcc=0.9020 ValAUC=0.9627\n",
            "Epoch  31/50 | TrainLoss=0.0757 ValF1=0.8942@0.32 | ValAcc=0.8899 ValAUC=0.9595\n",
            "Epoch  32/50 | TrainLoss=0.0723 ValF1=0.8905@0.42 | ValAcc=0.8879 ValAUC=0.9586\n",
            "Epoch  33/50 | TrainLoss=0.0669 ValF1=0.8945@0.33 | ValAcc=0.8909 ValAUC=0.9595\n",
            "Epoch  34/50 | TrainLoss=0.0593 ValF1=0.8928@0.47 | ValAcc=0.8905 ValAUC=0.9586\n",
            "Epoch  35/50 | TrainLoss=0.0511 ValF1=0.8915@0.58 | ValAcc=0.8901 ValAUC=0.9565\n",
            "Epoch  36/50 | TrainLoss=0.0508 ValF1=0.8974@0.28 | ValAcc=0.8944 ValAUC=0.9605\n",
            "Epoch  37/50 | TrainLoss=0.0512 ValF1=0.8924@0.20 | ValAcc=0.8875 ValAUC=0.9606\n",
            "Epoch  38/50 | TrainLoss=0.0441 ValF1=0.8944@0.29 | ValAcc=0.8910 ValAUC=0.9593\n",
            "Epoch  39/50 | TrainLoss=0.0412 ValF1=0.8938@0.22 | ValAcc=0.8892 ValAUC=0.9585\n",
            "Epoch  40/50 | TrainLoss=0.0382 ValF1=0.8977@0.41 | ValAcc=0.8959 ValAUC=0.9597\n",
            "Epoch  41/50 | TrainLoss=0.0377 ValF1=0.8998@0.45 | ValAcc=0.8969 ValAUC=0.9613\n",
            "Epoch  42/50 | TrainLoss=0.0358 ValF1=0.8980@0.50 | ValAcc=0.8951 ValAUC=0.9598\n",
            "Epoch  43/50 | TrainLoss=0.0321 ValF1=0.8980@0.26 | ValAcc=0.8949 ValAUC=0.9602\n",
            "Epoch  44/50 | TrainLoss=0.0302 ValF1=0.8966@0.31 | ValAcc=0.8939 ValAUC=0.9596\n",
            "Epoch  45/50 | TrainLoss=0.0256 ValF1=0.8947@0.13 | ValAcc=0.8901 ValAUC=0.9597\n",
            "Epoch  46/50 | TrainLoss=0.0253 ValF1=0.8985@0.26 | ValAcc=0.8958 ValAUC=0.9584\n",
            "Epoch  47/50 | TrainLoss=0.0252 ValF1=0.8966@0.39 | ValAcc=0.8951 ValAUC=0.9610\n",
            "Epoch  48/50 | TrainLoss=0.0225 ValF1=0.8951@0.16 | ValAcc=0.8915 ValAUC=0.9595\n",
            "Epoch  49/50 | TrainLoss=0.0206 ValF1=0.8980@0.27 | ValAcc=0.8958 ValAUC=0.9606\n",
            "Epoch  50/50 | TrainLoss=0.0186 ValF1=0.8986@0.24 | ValAcc=0.8952 ValAUC=0.9610\n",
            "\n",
            "ðŸŽ¯ Training complete. Best Val F1 = 0.9048 @ Thr = 0.31\n"
          ]
        }
      ],
      "source": [
        "# ==================== 1. Imports ====================\n",
        "import os, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.amp import autocast, GradScaler\n",
        "from PIL import Image\n",
        "\n",
        "# ==================== 2. Config ====================\n",
        "CONFIG = {\n",
        "    \"train_pkl\":         \"train.pkl\",  # must exist in working dir\n",
        "    \"epochs\":            50,\n",
        "    \"batch_size\":        64,\n",
        "    \"resize\":            (96, 96),\n",
        "    \"random_seed\":       42,\n",
        "    \"val_split_ratio\":   0.2,\n",
        "    \"num_workers\":       2,\n",
        "    \"pin_memory\":        True,\n",
        "    \"lr_backbone\":       1e-4,\n",
        "    \"lr_classifier\":     2e-4,\n",
        "    \"weight_decay\":      1e-4,\n",
        "    \"scheduler_T_0\":     10,\n",
        "    \"scheduler_T_mult\":  2,\n",
        "    \"scheduler_eta_min\": 1e-6,\n",
        "    \"dropout_1\":         0.3,\n",
        "    \"dropout_2\":         0.15,\n",
        "}\n",
        "\n",
        "# ==================== 3. Dataset ====================\n",
        "class RPSDataset(Dataset):\n",
        "    def __init__(self, X1, X2, y, resize, is_train):\n",
        "        self.X1 = X1\n",
        "        self.X2 = X2\n",
        "        self.y = y\n",
        "        self.resize = resize\n",
        "        self.is_train = is_train\n",
        "\n",
        "        self.normalize = transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "        self.augment = transforms.Compose([\n",
        "            transforms.RandomResizedCrop(resize, scale=(0.8,1.0)),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.RandomRotation(10),\n",
        "            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
        "        ]) if is_train else transforms.Resize(resize)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        def proc(img_np):\n",
        "            img = Image.fromarray(img_np.astype(np.uint8))  # grayscale HxW\n",
        "            img = self.augment(img)\n",
        "            x = self.to_tensor(img).repeat(3,1,1)  # to RGB 3Ã—HÃ—W\n",
        "            return self.normalize(x)\n",
        "\n",
        "        x1 = proc(self.X1[idx])\n",
        "        x2 = proc(self.X2[idx])\n",
        "        label = torch.tensor(self.y[idx], dtype=torch.float)\n",
        "        return x1, x2, label\n",
        "\n",
        "# ==================== 4. Siamese ResNet50 ====================\n",
        "class SiameseResNet50(nn.Module):\n",
        "    def __init__(self, drop1, drop2):\n",
        "        super().__init__()\n",
        "        backbone = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "        children = list(backbone.children())\n",
        "        self.initial = nn.Sequential(*children[:4])  # conv1 + bn1 + relu + maxpool\n",
        "        self.layer1 = children[4]\n",
        "        self.layer2 = children[5]\n",
        "        self.layer3 = children[6]\n",
        "        self.layer4 = children[7]\n",
        "        self.avgpool = children[8]\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.dropout1 = nn.Dropout(drop1)\n",
        "        self.dropout2 = nn.Dropout(drop2)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(2048*2, 512),\n",
        "            nn.ReLU(),\n",
        "            self.dropout1,\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            self.dropout2,\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.initial(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        return self.flatten(x)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        f1 = self.encode(x1)\n",
        "        f2 = self.encode(x2)\n",
        "        x = torch.cat([f1, f2], dim=1)\n",
        "        return self.classifier(x).squeeze(1)\n",
        "\n",
        "# ==================== 5. Training ====================\n",
        "def train_and_evaluate(cfg):\n",
        "    # Setup\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    torch.manual_seed(cfg[\"random_seed\"])\n",
        "    np.random.seed(cfg[\"random_seed\"])\n",
        "    if device.type == \"cuda\":\n",
        "        torch.cuda.manual_seed_all(cfg[\"random_seed\"])\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "\n",
        "    # Load & split data\n",
        "    df = pd.read_pickle(cfg[\"train_pkl\"])\n",
        "    df[\"label\"] = (df[\"label\"] == 1).astype(int)\n",
        "    y_all = df[\"label\"].values\n",
        "    X1_all = np.stack(df[\"img1\"].values).astype(\"float32\")\n",
        "    X2_all = np.stack(df[\"img2\"].values).astype(\"float32\")\n",
        "    del df; gc.collect()\n",
        "\n",
        "    # Weight balance\n",
        "    pos = (y_all == 1).sum()\n",
        "    neg = (y_all == 0).sum()\n",
        "    pos_weight = torch.tensor([neg/pos], device=device)\n",
        "\n",
        "    # Split\n",
        "    n = len(y_all)\n",
        "    idx = np.arange(n); np.random.shuffle(idx)\n",
        "    split = int((1 - cfg[\"val_split_ratio\"]) * n)\n",
        "    tr_idx, val_idx = idx[:split], idx[split:]\n",
        "\n",
        "    train_ds = RPSDataset(X1_all[tr_idx], X2_all[tr_idx], y_all[tr_idx], resize=cfg[\"resize\"], is_train=True)\n",
        "    val_ds   = RPSDataset(X1_all[val_idx], X2_all[val_idx], y_all[val_idx], resize=cfg[\"resize\"], is_train=False)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=cfg[\"batch_size\"], shuffle=True,\n",
        "                              num_workers=cfg[\"num_workers\"], pin_memory=cfg[\"pin_memory\"], drop_last=True)\n",
        "    val_loader = DataLoader(val_ds, batch_size=cfg[\"batch_size\"], shuffle=False,\n",
        "                            num_workers=cfg[\"num_workers\"], pin_memory=cfg[\"pin_memory\"])\n",
        "\n",
        "    # Model\n",
        "    model = SiameseResNet50(cfg[\"dropout_1\"], cfg[\"dropout_2\"]).to(device)\n",
        "    optimizer = optim.AdamW([\n",
        "        {\"params\": model.initial.parameters()},\n",
        "        {\"params\": model.layer1.parameters()},\n",
        "        {\"params\": model.layer2.parameters()},\n",
        "        {\"params\": model.layer3.parameters()},\n",
        "        {\"params\": model.layer4.parameters()},\n",
        "        {\"params\": model.classifier.parameters(), \"lr\": cfg[\"lr_classifier\"]},\n",
        "    ], lr=cfg[\"lr_backbone\"], weight_decay=cfg[\"weight_decay\"])\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "        optimizer, T_0=cfg[\"scheduler_T_0\"], T_mult=cfg[\"scheduler_T_mult\"],\n",
        "        eta_min=cfg[\"scheduler_eta_min\"]\n",
        "    )\n",
        "    criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    # Training\n",
        "    best_f1, best_thr = 0.0, 0.5\n",
        "    for epoch in range(1, cfg[\"epochs\"]+1):\n",
        "        model.train(); total_loss = 0.0\n",
        "        for x1, x2, yb in train_loader:\n",
        "            x1, x2, yb = x1.to(device), x2.to(device), yb.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            with autocast(device_type=device.type, enabled=(device.type==\"cuda\")):\n",
        "                logits = model(x1, x2)\n",
        "                loss = criterion(logits, yb)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            total_loss += loss.item()\n",
        "        train_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        model.eval(); all_probs, all_labels = [], []\n",
        "        with torch.no_grad():\n",
        "            for x1, x2, yb in val_loader:\n",
        "                x1, x2 = x1.to(device), x2.to(device)\n",
        "                with autocast(device_type=device.type, enabled=(device.type==\"cuda\")):\n",
        "                    logits = model(x1, x2)\n",
        "                probs = torch.sigmoid(logits).cpu().numpy()\n",
        "                all_probs.append(probs)\n",
        "                all_labels.append(yb.numpy())\n",
        "\n",
        "        all_probs = np.concatenate(all_probs)\n",
        "        all_labels = np.concatenate(all_labels).astype(int)\n",
        "\n",
        "        cur_thr, cur_f1 = 0.5, 0.0\n",
        "        for t in np.linspace(0.1, 0.9, 81):\n",
        "            p = (all_probs > t).astype(int)\n",
        "            f = f1_score(all_labels, p)\n",
        "            if f > cur_f1:\n",
        "                cur_f1, cur_thr = f, t\n",
        "        cur_acc = accuracy_score(all_labels, (all_probs > cur_thr).astype(int))\n",
        "        cur_auc = roc_auc_score(all_labels, all_probs)\n",
        "\n",
        "        print(f\"Epoch {epoch:3d}/{cfg['epochs']} | TrainLoss={train_loss:.4f} \"\n",
        "              f\"ValF1={cur_f1:.4f}@{cur_thr:.2f} | ValAcc={cur_acc:.4f} ValAUC={cur_auc:.4f}\")\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Save best\n",
        "        if cur_f1 > best_f1:\n",
        "            best_f1, best_thr = cur_f1, cur_thr\n",
        "            torch.save(model.state_dict(), \"siamese_resnet50_best.pt\")\n",
        "            print(f\"  âœ… New best model at epoch {epoch}! Saved to 'siamese_resnet50_best.pt'\")\n",
        "\n",
        "    print(f\"\\nðŸŽ¯ Training complete. Best Val F1 = {best_f1:.4f} @ Thr = {best_thr:.2f}\")\n",
        "    return model\n",
        "\n",
        "# ==================== 6. Run ====================\n",
        "if __name__ == \"__main__\":\n",
        "    train_and_evaluate(CONFIG)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os, gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.amp import autocast\n",
        "from PIL import Image\n",
        "\n",
        "# ---------------- Config ----------------\n",
        "CONFIG = {\n",
        "    \"batch_size\":     64,\n",
        "    \"resize\":         (96, 96),\n",
        "    \"num_workers\":    2,\n",
        "    \"pin_memory\":     True,\n",
        "    \"dropout_1\":      0.3,\n",
        "    \"dropout_2\":      0.15,\n",
        "    \"resize\":         (96, 96),\n",
        "}\n",
        "\n",
        "# ---------------- Dataset ----------------\n",
        "class RPSDataset(Dataset):\n",
        "    def __init__(self, X1, X2, y, resize):\n",
        "        self.X1 = X1\n",
        "        self.X2 = X2\n",
        "        self.y = y\n",
        "        self.resize = resize\n",
        "        self.normalize = transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])\n",
        "        self.to_tensor = transforms.ToTensor()\n",
        "        self.resize_tf = transforms.Resize(resize)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X1)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        def proc(img_np):\n",
        "            img = Image.fromarray(img_np.astype(np.uint8))  # HxW\n",
        "            img = self.resize_tf(img)\n",
        "            x = self.to_tensor(img).repeat(3,1,1)\n",
        "            return self.normalize(x)\n",
        "\n",
        "        x1 = proc(self.X1[idx])\n",
        "        x2 = proc(self.X2[idx])\n",
        "        return x1, x2\n",
        "\n",
        "# ---------------- Model ----------------\n",
        "class SiameseResNet50(nn.Module):\n",
        "    def __init__(self, drop1, drop2):\n",
        "        super().__init__()\n",
        "        backbone = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)\n",
        "        children = list(backbone.children())\n",
        "        self.initial = nn.Sequential(*children[:4])\n",
        "        self.layer1 = children[4]\n",
        "        self.layer2 = children[5]\n",
        "        self.layer3 = children[6]\n",
        "        self.layer4 = children[7]\n",
        "        self.avgpool = children[8]\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.dropout1 = nn.Dropout(drop1)\n",
        "        self.dropout2 = nn.Dropout(drop2)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(2048 * 2, 512),\n",
        "            nn.ReLU(),\n",
        "            self.dropout1,\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            self.dropout2,\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.initial(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.avgpool(x)\n",
        "        return self.flatten(x)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        f1 = self.encode(x1)\n",
        "        f2 = self.encode(x2)\n",
        "        x = torch.cat([f1, f2], dim=1)\n",
        "        return self.classifier(x).squeeze(1)\n",
        "\n",
        "# ---------------- Inference ----------------\n",
        "def predict_test_data(cfg, model_path, test_pkl_path, output_csv_path=\"submission.csv\"):\n",
        "    if not os.path.exists(model_path):\n",
        "        print(f\"âŒ Model file not found: {model_path}\")\n",
        "        return\n",
        "    if not os.path.exists(test_pkl_path):\n",
        "        print(f\"âŒ Test file not found: {test_pkl_path}\")\n",
        "        return\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Rebuild and load model weights\n",
        "    model = SiameseResNet50(cfg[\"dropout_1\"], cfg[\"dropout_2\"])\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(f\"âœ… Model loaded from {model_path}\")\n",
        "\n",
        "    # Load test.pkl\n",
        "    df = pd.read_pickle(test_pkl_path)\n",
        "    if \"img1\" not in df.columns or \"img2\" not in df.columns:\n",
        "        print(\"âŒ test.pkl must contain 'img1' and 'img2' columns.\")\n",
        "        return\n",
        "    if \"id\" not in df.columns:\n",
        "        df[\"id\"] = np.arange(len(df))\n",
        "\n",
        "    X1 = np.stack(df[\"img1\"].values).astype(\"float32\")\n",
        "    X2 = np.stack(df[\"img2\"].values).astype(\"float32\")\n",
        "\n",
        "    dataset = RPSDataset(X1, X2, y=None, resize=cfg[\"resize\"])\n",
        "    loader = DataLoader(dataset, batch_size=cfg[\"batch_size\"],\n",
        "                        shuffle=False, num_workers=cfg[\"num_workers\"],\n",
        "                        pin_memory=cfg[\"pin_memory\"])\n",
        "\n",
        "    # Predict\n",
        "    all_probs = []\n",
        "    with torch.no_grad():\n",
        "        for x1, x2 in loader:\n",
        "            x1, x2 = x1.to(device), x2.to(device)\n",
        "            with autocast(device_type=device.type, enabled=(device.type == \"cuda\")):\n",
        "                logits = model(x1, x2)\n",
        "            probs = torch.sigmoid(logits).cpu().numpy()\n",
        "            all_probs.append(probs)\n",
        "\n",
        "    probs = np.concatenate(all_probs)\n",
        "    preds = np.where(probs >= 0.5, 1, -1)\n",
        "\n",
        "    # Save\n",
        "    df_out = pd.DataFrame({\n",
        "        \"id\": df[\"id\"],\n",
        "        \"labels\": preds\n",
        "    })\n",
        "    df_out.to_csv(output_csv_path, index=False)\n",
        "    print(f\"âœ… Submission saved to {output_csv_path}\")\n",
        "\n",
        "    # Cleanup\n",
        "    del model, dataset, loader, df, X1, X2\n",
        "    gc.collect()\n",
        "    if device.type == 'cuda':\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "# ---------------- Run ----------------\n",
        "if __name__ == \"__main__\":\n",
        "    MODEL_FILE_PATH = \"siamese_resnet50_best.pt\"\n",
        "    TEST_DATA_PATH = \"test.pkl\"\n",
        "    OUTPUT_CSV_PATH = \"submission_resnet50_probably_best_of_day1.csv\"\n",
        "\n",
        "    predict_test_data(CONFIG, MODEL_FILE_PATH, TEST_DATA_PATH, OUTPUT_CSV_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-KTqvAizgEr",
        "outputId": "1d6f590f-ccb7-4aac-c87b-0c068440d9dc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "âœ… Model loaded from siamese_resnet50_best.pt\n",
            "âœ… Submission saved to submission_resnet50_probably_best_of_day1.csv\n"
          ]
        }
      ]
    }
  ]
}